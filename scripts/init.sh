#!/bin/bash

set -e

echo "ğŸš€ Iniciando el sistema de anÃ¡lisis de viajes de taxi..."

# Esperar a que Hadoop estÃ© listo
echo "â³ Esperando a que HDFS estÃ© listo..."
sleep 30

# Crear directorios en HDFS
echo "ğŸ“ Creando directorios en HDFS..."
docker exec hadoop-namenode hdfs dfs -mkdir -p /data/nyc/raw
docker exec hadoop-namenode hdfs dfs -mkdir -p /data/nyc/processed
docker exec hadoop-namenode hdfs dfs -mkdir -p /data/nyc/analytics

# Verificar si los datos ya estÃ¡n cargados
echo "ğŸ“Š Verificando si los datos raw ya existen en HDFS..."
if ! docker exec hadoop-namenode hdfs dfs -test -d /data/nyc/raw/taxi-trips; then
    echo "ğŸ“¥ Cargando datos en HDFS..."
    docker exec spark-master spark-submit --master spark://spark-master:7077 /opt/spark-apps/load_to_hdfs.py
else
    echo "âœ… Datos ya existen en HDFS."
fi

# Limpiar datos
echo "ğŸ§¹ Ejecutando limpieza de datos..."
docker exec spark-master spark-submit --master spark://spark-master:7077 /opt/spark-apps/clean_data.py

# Ejecutar anÃ¡lisis bÃ¡sicos
echo "ğŸ“ˆ Ejecutando anÃ¡lisis bÃ¡sicos..."
docker exec spark-master spark-submit --master spark://spark-master:7077 /opt/spark-apps/analytics_basic.py

# Ejecutar anÃ¡lisis intermedios
echo "ğŸ“Š Ejecutando anÃ¡lisis intermedios..."
docker exec spark-master spark-submit --master spark://spark-master:7077 /opt/spark-apps/analytics_intermediate.py

# Ejecutar anÃ¡lisis avanzados (V2)
echo "ğŸš€ Ejecutando anÃ¡lisis avanzados para API V2..."
docker exec spark-master spark-submit --master spark://spark-master:7077 /opt/spark-apps/analytics_advanced.py

echo "âœ… Proceso de inicializaciÃ³n completado exitosamente."
echo "ğŸŒ La API REST estÃ¡ disponible en http://localhost:3000/api"